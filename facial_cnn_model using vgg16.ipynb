{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "base_dir = '/home/tech-iguana/Documents/facial_stuff/tf_facial_model/images/train'\n",
    "\n",
    "CATEGORIES = [\"keith\", \"martin\",\"keithmartin\", \"jay\", \"rodney\", \"florence\", \"denzel\", \"sylvia\", \"albert\", \"luidgi\"]\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(base_dir, category) #with the iterator named cartegory we are able to loop over files of diffrent people.\n",
    "    for img in os.listdir(path):  # gets the images of diffrent people store in diffrent folders\n",
    "        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "        plt.imshow(img_array, cmap='gray')  # shows the image in a scale\n",
    "        plt.show()  # display!\n",
    "\n",
    "        break  # we just want one for now so break\n",
    "    break  #...and one more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 254 254 ... 255 254 255]\n",
      " [255 251 255 ... 255 255 254]\n",
      " [254 255  97 ...  65  64 254]\n",
      " ...\n",
      " [255 255 211 ...  40  39 255]\n",
      " [255 254 213 ...  41  40 255]\n",
      " [253 255 251 ... 254 255 253]]\n"
     ]
    }
   ],
   "source": [
    "print(img_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 138)\n"
     ]
    }
   ],
   "source": [
    "print(img_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resizing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAfxUlEQVR4nO2dXayeVZXH/8tSaCkt/S6lp3KKIILSAT0hTeRCqSQMGOHCSVAz6SQk3MwYjE60ziSTmMwF3qgXM2oaIXYSA4qaQIiTCWlpjYFUiyAfrdgW+0VLT2tbBT/4cs/FeUve57/XOXud55zzvu9x/39J07Of83ysdz/PPs/7X3uttS2lBCHE3z7v6rcBQojeoMEuRCVosAtRCRrsQlSCBrsQlaDBLkQlTGmwm9ktZvaime03s83TZZQQYvqxtvPsZjYHwG8A3AzgKIBfAPhUSmnPeMcsX748DQ8Pt7qeEKLMwYMHcerUKfN+d94UznsDgP0ppZcAwMweBHA7gHEH+/DwMHbt2vVOe86cOZO+qPfHibe9611/++ok8kfazL3nPWe6bO3XZ/auW7pOm2Omg5GRkXF/N5VRsQbAka720c42IcQAMpXB7v2Zyv6cmdndZrbbzHafPHlyCpcTQkyFqXyNPwpgbVd7CMAx3imltAXAFgAYGRlJ3V+x77zzzuykb7/9dqP95JNPNtrz58/Pjtm4cWOjfcEFF2T7sGSYqZwA/qp23nnNLvbsX7BgQaN94YUXFo+5+OKLG+3zzz8/24c/I/dL5BjG+yr65ptvNtpvvPFGo/2Xv/wlO+bMmTON9muvvVY879mzZ4u28vPD7Zniueeea7S9zxyBPxO3//rXv2bHrFix4p2f9+/fP+65p/Jm/wWAK81snZmdD+BOAI9M4XxCiBmk9Zs9pfSWmf0LgP8DMAfA/SmlF6bNMiHEtDKVr/FIKf0EwE+myRYhxAzytz9HJYQAMMU3exu6HTye84QdQOycuuSSS7JjeF69zfy95/hoA1+bz+vFAMydO3fCc/DvvW2R2ALu2zbOK6+f+DyR+WR2FrJTD8idU/yZ2YHXS956662eXCfyXHY7gSfqe73ZhagEDXYhKkGDXYhK6Llm79Ygnk47ffr0hMdzMAngB9GUYG3jad7p0PF8Xk8nlwIpPNg2z09R8h+08W14sH7lvvWCd7gfvGeB+46vw0E2QB7ExOfw+raN/ua+W7t2baO9b9++7Bjuf09ftwn2ih6jN7sQlaDBLkQlaLALUQl9nWePJAuwHp83b162D+s/1m2TtWs8WBtFjokk4JR8A5E5dM8XwPPS3I5oxsjcPG8r+QqA/B55/oOSlvbiD3juPdJ3vA/b+/rrrxevw/3m+SAitPETdff/RPpdb3YhKkGDXYhK0GAXohI02IWohJ476LrxnD3soGAHnefAiASltCn216Zw5XQk5bRxyHmOS/7MEecVHxPp28g9YtoE+PA+3j1lx1+k0kubZ6MUyOIFErFDOmJLxP5uR6YcdEIIDXYhakGDXYhK6GtQzZ///Ofs96xFWftEFonwdA3r05lKhOFjuB3R1hE7Ilq6ZL/nM2HNy3rcs5UDSLjt9S0HqrQpvuHp/FKATOQ6rK0j9rNtCxcuzI7hCrptnq+pPKd6swtRCRrsQlSCBrsQlaDBLkQl9DWoxstqapNBxUQcdBEiQRxMaR/PDv7MkYombZw7fJ7I52Fnm3dM6bzeZ2ZHoHdezmorOQ+B3FEZqULDwUZ8370qtmxLpNIt92Wb57T0LCioRgihwS5ELWiwC1EJfdXsXjUP1j6sUTydw+fxkhA4CMKrclKCz+tVxGkT1FFaESaiZyNJFWxvZMnmiM4vJbV4OpJX+vG0Nd9XDkiKVKrhdqRqTsRnwp+RA8S8Z6Nt9ZpuvOen+zNKswshNNiFqAUNdiEqoeeavVtTeKtmLFmypNHmVVs9LcQJBosWLcr2mY6iEqwrvXne0nnbzCd75+R9vH4pnTfityj5IIA8ToD1eGQOOjKXzQkqv/vd77JjSv6PSFILa2uvn/74xz9OaKvngzhz5kyj7fUl28vP9oIFC7Jjuq89UVyB3uxCVIIGuxCVoMEuRCUUB7uZ3W9mo2b2fNe2pWb2mJnt6/y/ZKJzCCH6T8RB910A/wXgf7q2bQawLaV0r5lt7rS/FLngZCt5cpBAZMljz0lRCvSYruqzHKgSCTBhSss2AblD6MILLyyeJ5KgwkQcm6WKrp4j809/+lOj7Tme+DwcVOM9C+w4i/yen5eIg5T7lh2MF110UXbMH/7wh0Y7Ut2XYYcd0HRqTymoJqX0UwC8aPrtALZ2ft4K4I7SeYQQ/aWtZl+VUjoOAJ3/V463o5ndbWa7zWz3yZMnW15OCDFVZtxBl1LaklIaSSmNrFixYqYvJ4QYh7ZBNSfMbHVK6biZrQYwGj2wTcXTbjxNw5qLtRGQB3qwto6sLsJEklo8vVo6T0QnR5JySgUipmtFmIgfgolUDWY4+MV7lnjbq6++2mgfO3YsO4Z9AXzPvL5l+/m6XpIRP9te/0cqJTMzXbziEQCbOj9vAvBwy/MIIXpEZOrtAQBPArjKzI6a2V0A7gVws5ntA3Bzpy2EGGCKX+NTSp8a51cbp9kWIcQM0vNEmG6d4ulzTnbgffj3HqzPgVz7lOZW2VYg12He/DdvYz0Ymdtmje5dh/dpk9jTRn9HVp7he8Zz6kCui735b9bbBw4caLRPnDiRHXP06NFG++KLL260vfl8vielAipAfk/4uYw8g5GCI5MtcjrR/gqXFaISNNiFqAQNdiEqQYNdiEroa3VZz1nFjqbIih7sEPKqeJYqiXhBEJ6TpRuvukppRRtvyebSksfe0taRBJtSldo2iTCRIA/ug7Nnz2b7sC1PPfVUts9vf/vbRpuTQCKr63Dbq2LE95mP8Zy3o6MTx5FFKgd5lIKaIseMh97sQlSCBrsQlaDBLkQl9FWze5R0pKdh2mhR1rORVWQ4EMRLquBtrBEXLlyYHbNs2bJGmwM/vMIUbMvSpUuL+7CPwfvMbYJzGE5EOnXqVLYPpzsfPnw424e1filJCsiLRlx22WWNttf/pSAazzfD+rvkKwByfw0/XzON3uxCVIIGuxCVoMEuRCUM3Dw7z39H5hl5H++8vI3nQUuFCoE8McOzjTU6r1rirWJy8ODBCa/rxQ2wRueEDyBfTWf58uWNtpcUwtsifcv7cFKIN89+/PjxRjuiX0tFPgBg1apVjXZEJ3PsAGt0T3+X4g28hK0NGzY02tu2bcv2KRUJnQp6swtRCRrsQlSCBrsQlaDBLkQl9NVB5zm42DnCDrtI8kOk6ujvf//7RttLXGDnSKSiKwdtsL0vv/xydgzbwufwgjoOHTrUaHvONq7scsUVVzTa7373u7Nj2PHH9keCmtgJ5lX7Zaedl+zD5128eHGjfc0112THcBAN2+sFQvFSypxw4yVjlVaN8Z7B9773vY32rl27sn1KDmrvvJEgMkBvdiGqQYNdiErQYBeiEvqq2T39wUEFrOW8ABNOfvCSOVj38j5e4ATvw4klXiIJ2zI8PNxof+hDH8qOYU3LSSFcMRXIg4AigR9HjhxptD2fA/cvB+uUVsnxbPMSYSK+mFKyknef2f5SwI9nCz9zXlDQypXN5Q3Z/sjKRXwOwPcpTHSdyaA3uxCVoMEuRCVosAtRCT3X7N0a6rbbbst+z5rK06sM66NIUcRIgkFpbt7T7AxrSO+6XJzife97X6PtaVPuF09XMrwyi9e3rMm5GGOkaGKp6CbgF95kWJ+yln7ooYeyY1gXs6/Gi1kozc2vXr06O4bvfURLc996K/y2WRFXBSeFEA002IWoBA12ISpBg12ISui5g67b6eU5e9ghxA4VL6gmEtAwkR3jwQ4hDg7Zu3dvdgxXSuHqMJ5jiqvXcLWbPXv2ZMcsWbKk0fZWr/ESULrx+oCdRuxs48/jwY7ASMKQV/WVz8OJMFztJnJt7jcA+OAHP9hoc7+tXbs2O4YddHxdrmrk4QXVcNUi7n/v2daSzUKIBhrsQlRCcbCb2Voze9zM9prZC2Z2T2f7UjN7zMz2df7Pvx8JIQaGiGZ/C8AXUkq/NLOFAJ4ys8cA/BOAbSmle81sM4DNAL5UOll3gIWneVlHrlixotH2gg5KhQQ8+Dye1mFfABeI8LQoB95wwAwXnQByvwRrUe/zfOADH2i0OckFANavX99os2/A05VcuOHSSy9ttD2dyYEs7NvwdDLrby+Rh3Xx0NBQo/3pT386O+bZZ5+d8BzeKq6cuMMFPLgPgHI1XO/37ANqE1jk0f0sTxSUUzxTSul4SumXnZ9fBbAXwBoAtwPY2tltK4A7ilYJIfrGpDS7mQ0DuB7ALgCrUkrHgbE/CADyP/lCiIEhPNjN7CIAPwLwuZTSxHM6zePuNrPdZrabF/MTQvSO0GA3s7kYG+jfSyn9uLP5hJmt7vx+NYBR79iU0paU0khKaYT1txCidxQddDbmuboPwN6U0te6fvUIgE0A7u38//BkL85LFQN5pc/pWtaWHXAchOJlsHGgB2fkjY7mf9/YucOVajwH186dOxttdurdeOON2TGXX355o83BPEDZ2elVumXY4eM50thRyU4lrt7jnccLqlmzZk2jzd8MvUw/vs/sfPMCibjvOIjGc97y88L7sKMTyANv+NkAgO3btzfabQLGxiPijf8wgH8E8JyZPdPZ9m8YG+Q/MLO7ABwG8A+trRBCzDjFwZ5S+hmA8f6cbJxec4QQM4Ui6ISohL5WqoksGcyBCN7Syqz/vAQbDkzhoI5IsgbvwxVOgFxXcuKOF6Dx2c9+dkJbvc/MWpr1LZBrWj6Pp6UZtt+rzsrnYV3sBQWx/V6CE9/Ha6+9tmgLBw6x5vVsYR8J7+PZxoFQrOG9xCTufy/Ah59lfuZKK/IoEUYIocEuRC1osAtRCX1dEcabc2aNznPZnhZivLlUTjpgLeTN8/JqKKXEDCDXzjyX7UURcuILF4jgOXUgr3jqzesy3Aee5mXNyHEO3uourNn5HN7cPOPFOZRW2vXuGd8T1t/eiqylQiZeMgqfJ1JRlwuDeDEkpQStqcyz680uRCVosAtRCRrsQlSCBrsQldBXBx0HMwB5IMUVV1zRaHsOOnbqeU4YPi87OrxAnJLTxQtw4EAJdqRFquhE4KAOTrKIELGFnVNe8BFfmxNuvCo6jBe4wvea76uXCMPOwsgSXaVqMF4/tUlQ4efJqxTE/SsHnRBi0miwC1EJGuxCVELPNXu35vCCGTi5hDUX63MAeP7558e9xjlKusz7PWs13sfTmawr2f6IbyCiy9hf4FUq5aANDlIpJVV4eIEgfB85ycgr8sH95PlZSglO3j1jXwbbFrnPbXQxX6e0cst4eMs4d+Pds0gFWkBvdiGqQYNdiErQYBeiEvo6z3748OFsG+s91mneyqSRJATWS6yxInPzTGT+lW3z5sNLc6kRrefNf/Nx/BkjupI1pBcbwftwv3kJT6dPn57QNiBP1OG+9ObQ2/RdKVHH08nsG4isNszX8XxWvI3vq3dM1MegN7sQlaDBLkQlaLALUQka7EJUQl+ry27YsCH7PTtuOBDEq65Scr4BuQOInS6eg4idLJGgjlJFnDZEgiY8J1MkcKUEV4Ph6j3eNu6nSKUaL6mF7yM7Nz0H3UwEyHjONn4OOdjIc8TyNu9ZbhP8FUVvdiEqQYNdiErQYBeiEvqaCOPpKQ7aYF0T0cCeNi3pPS+AhoNFWA96QTVtNCPvEymMwD4HT/9xxdlI8Q3uB+4nL+GGV7lhjc4BJ0CucT1dzPeMV1Tx9CuvKNRGs3O/ePbzPpygFTnGqwhcuvdtkpfeOXdoLyHErEeDXYhK0GAXohL6Os/uaV7WhNz25my5yCCv5AmU50W9OVvWiBHNW5pn93wOkTl/hvvB0388d822eavosn3cL95n5n5hvRrxOUSKb7Cu93Qx7xPRvKUVYbxj2J/A98O7h3yPIvPsbFvJ1onQm12IStBgF6ISNNiFqITiYDezeWb2czP7lZm9YGZf6WxfZ2a7zGyfmX3fzMrV+IUQfSPioHsdwE0ppdfMbC6An5nZ/wL4PICvp5QeNLNvA7gLwLdKJ+t2mHhBEewQ4n08pwY7dyIVQNj55jnO+Npsm+d4KjmR2iQyeMfw5/GcSFzVh4OEvPPyZ2JHlFcplgOhli1bNuE5gPw+eveM+45XUPGWbObzRpKkSngBP2wLB9Xw8wXkDkevUnIb+7x771F88tIY59yIczv/EoCbAPyws30rgDsmbaUQomeEXjNmNsfMngEwCuAxAAcAnE0pnZtfOApgzTjH3m1mu81s98mTJ6fDZiFEC0KDPaX0dkrpOgBDAG4AcLW32zjHbkkpjaSURnjBPyFE75hUUE1K6ayZ7QCwAcBiMzuv83YfAnBs0hd3dDIHJ3BhBC5uAeT6yAu84cAP1ksRW/gc3jGs5VgXewk3vA+3I8kPXoBSKYhjyZIl2TGlZJ9Vq1Zlxxw71rz1fD+8whRcWXjPnj3F8958882NttcvJf3q+Vn4PnPb09alVXS9lXP4fnj+Dyayos20JcKY2QozW9z5eT6AjwHYC+BxAJ/s7LYJwMOhKwoh+kLkzb4awFYzm4OxPw4/SCk9amZ7ADxoZv8J4GkA982gnUKIKVIc7CmlZwFc72x/CWP6XQgxC1AEnRCV0NesN8/ZUAo6uf767EtGlmHkLRG1ffv2RjuSTbd8+fJGmx1cXuAEO0vYiedlanGwS6lyjbfNC/wYGhpqtHfv3t1o79y5MzuG+4GdeJ5T7z3veU+jzUE13mc+ePBgcZ/3v//9jba39BRTWv7Jc+CVlujiCsdA7rTj/j9z5kzxOidOnMj2YTzHa1v0ZheiEjTYhagEDXYhKmHgqssyHITiJQqwfmWtDeRBDpEqtZ7278arrlJKxPAq4vBnLC0V7eHpek4U2bhxY6N93XXXZcdw4MfRo0cb7Zdffjk7hn0BrNnXrl2bHcPaf9GiRdk+vNTzdCS1eJqdfS8lPQ7kOp6fFa9SDV87EvwVSXLpfpYnGlN6swtRCRrsQlSCBrsQldBzzd6NN4cYTcTvpjS3CgBLly5ttCO6jG1hve3NpbKOjOhx1vkR3RYpXsE+BS8ugOHz8GovPHcP5MlK3LdewRG236uOy1WDPR8Jw/ZH5tnZXtbjXgwA2+s9PwzreO/5j9jLRH0XerMLUQka7EJUgga7EJWgwS5EJQzc8k/skIg4KCLHcGDH/v37G+1IBRN2yEUqpbCTyQvm4X6IVF4tXRcoJ3h4DrtSRd1IwA870rxAIq5e49n/yiuvNNrcL15iTMmJ18Yp7DkY2WnH7cg98565kuO1zRLU59CbXYhK0GAXohI02IWohL4mwkSSUZiIFvL2ufLKKxvtX//61422Zwvro5KGB3KNxRoxkvzAARqR5B/vvBwswpV5I/3PGj1S3bS07DBQ7icg/0y8FLdXaZiDp9h+L/iF+4H38arjsv18Du9+cDVZT39HKgu3RW92ISpBg12IStBgF6ISBi4RhmG95x3D+3hatLT0VGTOvKThAT+hoxtv5VHWhHwdLkjpXcezhVenYT3r9WVpdZpLLrkkO4YLT0SKbHIRjFOnTmX7MPwZPc3OSSys2TnuwSMS58Db+J558/281qF3z9rMo0dXBtabXYhK0GAXohI02IWoBA12ISph4B1007UiBp+HK64cOXIkO6YULOI5Rkqr03hOmdKSwd51OGCGk1yAvMouJ6R4ziCuwstOygMHDmTHsAOOnVOebZH7ysEt3tLJDDsuh4eHG+1I1R+2N3LP+POwMw7I+ynibGaUCCOEKKLBLkQlaLALUQl91exeIYQ2xSsiK4XwPh/96Ecb7fvvv79oXyQJhzU7B5h4K4WwNo0kkvA+nCQC5Ik6vHKqV1SCA3jmz58/YduDi2J4n5nx7jMHG7EO9gKlFixY0GizD8L7zGwv3w9Ps5cCWTzfBuOddybRm12IStBgF6ISwoPdzOaY2dNm9minvc7MdpnZPjP7vpnl34+EEAPDZDT7PQD2AjiX9fBVAF9PKT1oZt8GcBeAb03q4i2KV0xXMj8nhVx99dXZPnv37m202xQWYL3qJcqwjuQVVjx9yMdce+212T7cv5xs4tnCc7+sZ3llVSCfz2dfgafzeZs3f8wFJSOrpbDOZ3+H5z/ghJpI8RCGE3C860TiNEo6PlKkcjxCb3YzGwJwG4DvdNoG4CYAP+zsshXAHaErCiH6QvRr/DcAfBHAuT8hywCcTSmd+/N1FMAa70Azu9vMdpvZbi+qSAjRG4qD3cw+DmA0pfRU92ZnV/c7bUppS0ppJKU0UsopF0LMHBHR/GEAnzCzWwHMw5hm/waAxWZ2XuftPgTg2MyZKYSYKsXBnlL6MoAvA4CZfQTAv6aUPmNmDwH4JIAHAWwC8PBkL+5VYHGuP2Hb2xapZsqsX78+2/biiy9OeN42lUYiSRV8Dq4E49niXZc/s7fcMsNBKWvWNNUZOw+9Y9ixxr8HgEOHDjXaXLkGyBNfIo4odkpyH3BiEpBX9OH74T077IA7dqz5rmtbOTay/HjpvOPuF9rL50sAPm9m+zGm4e+bwrmEEDPMpOa+Uko7AOzo/PwSgBum3yQhxEygCDohKqGviTBeUE1JW0cCWSJamoNHHnjggeyYkkb0tFIb+7maKQeyeJqX7Y+s4lrqAyDXr2xbJMCHiz94lWNPnDjRaHsryvJnYp0c0bx8D71Kt3xe7jfvOeAkKT5vxLYIked9WoNqhBCzHw12ISpBg12IShj44hVtVm2NzDvu2LGj0faSQvg8kcSdUiFFT7dx4QnWkF7BhcWLFxdt8fRpN14/sX8gotlfeeWVRps1r3efSzoZKNsfeTb4HOyTAPICF6XrAnkiD6/0E1nhNxIzwqjgpBCiiAa7EJWgwS5EJWiwC1EJAxdUw0ScMOzU8Jw9vErJzp07i7ZwxRJ2KnnOKt7GDruIg4UDTEZHRyd9HSDvu4jzk51V7Lj0liL2HHDdeA4vvkfePmxv6TqefRzQ4wX4sC3slOQkFwC46qqrGu1169Y12t5y0kybFWEilYbHQ292ISpBg12IStBgF6ISBi6ohjUJ65qIhm+jhVifR/DOWapm6gXIMFy0wdNkfJ1IkE1E57Ne5X0iyT/sl4hobW8fPg/7Ezw4wYb70rvP/JnYR+IFyHBwDvc/F/AA8r6NJMvwPlF97qE3uxCVoMEuRCVosAtRCRrsQlRCzx103Q6HNss/tVk2GcidI22uzUQcZ9z2nEzsBGPbuPILkDu0+PN5sHMwkvXG14l85ogTKeK0K1Xz9Zxtpco0paxEIA/M8Y7he8Kf2asIXArSAqZveTMPvdmFqAQNdiEqQYNdiErouWbvDhrwdHNppZPIyicerGk56MFbKYSTQCKBK2xfG51ZshWIVTMt2eatyMMVWHgfb/nlki/A07xsv5cIw/4NbnsVabl/+ZjIkscRHwTvw9f1EobaEFmmutu+iRKt9GYXohI02IWoBA12ISph4BNhShrYO49XQfSJJ56Y8LyeLiv5CyIrdUaKVZSqmXIyB5D7O7x9SgkpnpZmjc7a09PsDPsYvHvGOj+iv0urvQD53DXb79nCRObiGbZt6dKl2T68Um0kHmGymn0i9GYXohI02IWoBA12ISpBg12ISuhrIoxXtaVUmcMLSvnmN7/ZaHvVWNlpNDQ01Gh7DpUjR4402rzEjxc4Uara4sFBNJEllxgv8Ibt4308Zxtv48QY7gOgnFQUCWTxzsHPB1eG9YKCVq9ePeF1IktbRyrKcDXZSy+9tNGO3HdeNgvIP3PkPCtXrnzn53379o27n97sQlSCBrsQlaDBLkQl2Ewmy2cXMzsJ4BCA5QDypTkGk9lkKzC77J1NtgKzw97LUkorvF/0dLC/c1Gz3SmlkZ5fuAWzyVZgdtk7m2wFZp+9jL7GC1EJGuxCVEK/BvuWPl23DbPJVmB22TubbAVmn70N+qLZhRC9R1/jhaiEng52M7vFzF40s/1mtrmX145gZveb2aiZPd+1bamZPWZm+zr/L+mnjecws7Vm9riZ7TWzF8zsns72QbV3npn93Mx+1bH3K53t68xsV8fe75tZeeXLHmFmc8zsaTN7tNMeWFsj9Gywm9kcAP8N4O8BXAPgU2Z2Ta+uH+S7AG6hbZsBbEspXQlgW6c9CLwF4AsppasBbADwz53+HFR7XwdwU0rp7wBcB+AWM9sA4KsAvt6x9wyAu/poI3MPgL1d7UG2tUgv3+w3ANifUnoppfQGgAcB3N7D6xdJKf0UwGnafDuArZ2ftwK4o6dGjUNK6XhK6Zedn1/F2EO5BoNrb0opnSvXO7fzLwG4CcAPO9sHxl4zGwJwG4DvdNqGAbU1Si8H+xoA3WlkRzvbBp1VKaXjwNgAA7CysH/PMbNhANcD2IUBtrfztfgZAKMAHgNwAMDZlNK5WlKD9Ex8A8AXAZxLm1uGwbU1RC8Hu5erp6mAKWJmFwH4EYDPpZTy4vcDRErp7ZTSdQCGMPZN72pvt95alWNmHwcwmlJ6qnuzs2vfbZ0MvcxnPwpgbVd7CMCxHl6/LSfMbHVK6biZrcbYW2kgMLO5GBvo30sp/bizeWDtPUdK6ayZ7cCYr2GxmZ3XeWMOyjPxYQCfMLNbAcwDsAhjb/pBtDVML9/svwBwZcejeT6AOwE80sPrt+URAJs6P28C8HAfbXmHjoa8D8DelNLXun41qPauMLPFnZ/nA/gYxvwMjwP4ZGe3gbA3pfTllNJQSmkYY8/p9pTSZzCAtk6KlFLP/gG4FcBvMKbV/r2X1w7a9wCA4wDexNg3kbswptW2AdjX+X9pv+3s2Hojxr5GPgvgmc6/WwfY3vUAnu7Y+zyA/+hsvxzAzwHsB/AQgAv6bSvZ/REAj84GW0v/FEEnRCUogk6IStBgF6ISNNiFqAQNdiEqQYNdiErQYBeiEjTYhagEDXYhKuH/AVsfVqeOb9t5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMG_SIZE = 50\n",
    "\n",
    "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "plt.imshow(new_array, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 106.24it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 321.39it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 856.57it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 536.33it/s]\n",
      "100%|██████████| 35/35 [00:00<00:00, 2087.61it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 723.89it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 238.24it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 231.69it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 250.65it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 298.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = []  \n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES: \n",
    "\n",
    "        path = os.path.join(base_dir, category)  # create path to diffrent folders of diffrent people that we want to use for the training set\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each images of diffrent people in diffrent folders\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "            #except OSError as e:\n",
    "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
    "            #except Exception as e:\n",
    "            #    print(\"general exception\", e, os.path.join(path,img))\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "6\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[251]\n",
      "   [255]\n",
      "   [254]\n",
      "   ...\n",
      "   [252]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[255]\n",
      "   [105]\n",
      "   [105]\n",
      "   ...\n",
      "   [ 81]\n",
      "   [ 80]\n",
      "   [ 91]]\n",
      "\n",
      "  [[255]\n",
      "   [106]\n",
      "   [106]\n",
      "   ...\n",
      "   [ 70]\n",
      "   [ 65]\n",
      "   [ 81]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[254]\n",
      "   [204]\n",
      "   [204]\n",
      "   ...\n",
      "   [ 41]\n",
      "   [ 40]\n",
      "   [ 51]]\n",
      "\n",
      "  [[255]\n",
      "   [211]\n",
      "   [211]\n",
      "   ...\n",
      "   [ 41]\n",
      "   [ 40]\n",
      "   [ 51]]\n",
      "\n",
      "  [[251]\n",
      "   [215]\n",
      "   [215]\n",
      "   ...\n",
      "   [ 54]\n",
      "   [ 51]\n",
      "   [ 63]]]]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "\n",
    "print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = img_width = 100\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " path = os.path.join(base_dir, category) #with the iterator named cartegory we are able to loop over files of diffrent people.\n",
    "    for img in os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 175s 3us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import applications\n",
    "\n",
    "#img_height = img_width = 100 \n",
    "#channels = 3\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "model = applications.VGG16(include_top=False, weights='imagenet')           #input_shape=(img_width, img_height, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_input to have shape (50, 50, 1) but got array with shape (224, 224, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f39813ced876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#print labels[prediction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    572\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    575\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_input to have shape (50, 50, 1) but got array with shape (224, 224, 3)"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "base_dirr = '/home/tech-iguana/Documents/facial_stuff/tf_facial_model/images/train/keith'\n",
    "\n",
    "\n",
    "\n",
    "img_path = os.path.join(base_dirr, 'keith,9012.13.jpg')\n",
    "\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "\n",
    "#prediction = prediction.data.numpy().argmax()  # Our prediction will be the index of the class label with the largest value.\n",
    "#print labels[prediction]\n",
    "\n",
    "features = model.predict(x)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44 samples, validate on 178 samples\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 4s 82ms/sample - loss: 16.1246 - accuracy: 0.1591 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 2s 53ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 2s 53ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 2s 55ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 2s 51ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 2s 51ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 2s 54ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 2s 52ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 2s 55ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 3s 69ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 3s 59ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 2s 56ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 2s 51ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 2s 51ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 2s 53ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 2s 55ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 3s 73ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 2s 56ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 2s 50ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 2s 54ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 2s 49ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 3s 69ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 3s 73ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 3s 68ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 3s 68ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 3s 74ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 2s 55ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 3s 65ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 3s 66ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 3s 67ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 3s 72ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 3s 66ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 3s 64ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 3s 65ms/sample - loss: 13.8409 - accuracy: 0.1136 - val_loss: 15.9551 - val_accuracy: 0.1180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f10ec1b22d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=50, validation_split=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 256)       2560      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 48, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1982528   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,575,233\n",
      "Trainable params: 2,575,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tech-iguana/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: attendancefacialmodel/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('attendancefacialmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Ignore this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = [\"keith\", \"martin\",\"keithmartin\", \"jay\", \"rodney\", \"florence\", \"denzel\", \"slyvia\", \"albert\", \"luidgi\"]\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 50  \n",
    "    img_array = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"attendancefacialmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Python inputs incompatible with input_signature:\n  inputs: (\n    Tensor(\"IteratorGetNext:0\", shape=(None, 50, 50, 1), dtype=uint8))\n  input_signature: (\n    TensorSpec(shape=(None, None, None, 1), dtype=tf.float32, name=None))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-42ff165fea45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnew_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'new_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    445\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1820\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 73\u001b[0;31m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 760\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2132\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_predict_on_batch\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_predict_on_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(model, x)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_learning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mreturn_outputs_and_add_losses\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs_arg_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs_arg_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1820\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2106\u001b[0m       args, kwargs = self._function_spec.canonicalize_function_inputs(\n\u001b[0;32m-> 2107\u001b[0;31m           *args, **kwargs)\n\u001b[0m\u001b[1;32m   2108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2109\u001b[0m     \u001b[0mcache_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcanonicalize_function_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_signature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m           self._flat_input_signature)\n\u001b[0m\u001b[1;32m   1651\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_convert_inputs_to_signature\u001b[0;34m(inputs, input_signature, flat_input_signature)\u001b[0m\n\u001b[1;32m   1714\u001b[0m       flatten_inputs)):\n\u001b[1;32m   1715\u001b[0m     raise ValueError(\"Python inputs incompatible with input_signature:\\n%s\" %\n\u001b[0;32m-> 1716\u001b[0;31m                      format_error_message(inputs, input_signature))\n\u001b[0m\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mneed_packing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Python inputs incompatible with input_signature:\n  inputs: (\n    Tensor(\"IteratorGetNext:0\", shape=(None, 50, 50, 1), dtype=uint8))\n  input_signature: (\n    TensorSpec(shape=(None, None, None, 1), dtype=tf.float32, name=None))"
     ]
    }
   ],
   "source": [
    "base_dir = '/home/tech-iguana/Documents/facial_stuff/tf_facial_model/images/test'\n",
    "\n",
    "img = os.path.join(base_dir,'martin,2019.5.jpg') \n",
    "\n",
    "IMG_SIZE = 50  \n",
    "img_array = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "prediction = model.predict([prepare('new_array')])\n",
    "\n",
    "#return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "\n",
    "\n",
    "#print(prediction)  # will be a list in a list.\n",
    "#print(CATEGORIES[int(prediction[0][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
